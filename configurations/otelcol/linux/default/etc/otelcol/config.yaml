receivers:
  otlp:
    protocols:
      grpc:
      http:
  hostmetrics:
    collection_interval: 60s
    scrapers:
      cpu:
        metrics:
          system.cpu.utilization:
            enabled: true
      memory:
        metrics:
          system.linux.memory.available:
            enabled: true
          system.memory.utilization:
            enabled: true
      disk:
      network:
      load:
      filesystem:
        include_virtual_filesystems: true
        metrics:
          system.filesystem.inodes.usage:
            enabled: true
          system.filesystem.usage:
            enabled: true
          system.filesystem.utilization:
            enabled: true
      paging:
      processes:
  prometheus:
    config:
      scrape_configs:
        - job_name: 'prom-metrics-collector'
          scrape_interval: 60s
          static_configs:
            - targets: ['0.0.0.0:9464']
  filelog/container:
    include: [ '{{$ .Agent.data.apicalogs.container.include }}' ]
    exclude_older_than: 4h
    operators:
      - type: regex_parser
        regex: '^(?<timestamp>[^ ]* [^ ]* [^ ]* [^ ]* [^ ]* [^ ]*) (?<loglevel>[^ ]*)[ ]*\[(?<javaprog>[^ ]*) (?<method>[^ ]*)\] (?<msg>.*)$'
        timestamp:
          parse_from: attributes.timestamp
          layout: '%b %g, %Y %l:%M:%S %p %Z'
        severity:
          parse_from: attributes.loglevel
          mapping:
            info: 
              - INFO
              - FINE
            warn:
              - WARN
              - WARNING
            error:
              - ERROR
              - FATAL
              - EMERGENCY
    retry_on_failure:
      enabled: true
processors:
  resource/os:
    attributes:
      - key: ostype
        value: "linux"
        action: upsert
  resource/boomi:
    attributes:
      - key: host.name
        value: "{{$ .Agent.host_name }}"
        action: upsert
      - key: customer.id
        value: "{{$ .Agent.data.customer_id }}"
        action: upsert
      - key: runtime.id
        value: "{{$ .Agent.data.runtime_id }}"
        action: upsert
  resource/apicalogs:
    attributes:
      - key: namespace
        action: insert
        value: "{{$ .Agent.data.namespace }}"
      - key: application
        action: insert
        value: "{{$ .Agent.data.application }}"
exporters:
  debug:
    verbosity: detailed
  prometheus:
    endpoint: 0.0.0.0:9464
  apica/logs:
    endpoint: "{{$ .Agent.secret.apicalogs.endpoint }}"
    tls:
      insecure: false
      insecure_skip_verify: true
    headers:
      Authorization: "Bearer {{$ .Agent.secret.apicalogs.token }}"
    sending_queue:
      enabled: true
      queue_size: 1_000_000
    retry_on_failure:
      enabled: true
  prometheusremotewrite/apicametrics:
    endpoint: "{{$ .Agent.secret.apicametrics.endpoint }}"
    tls:
      insecure: false
      insecure_skip_verify: true
    external_labels:
      customer: "{{$ .Agent.data.customer_id }}"
      runtime: "{{$ .Agent.data.runtime_id }}"
      hostname: "{{$ .Agent.host_name }}"
      ostype: "linux"
    resource_to_telemetry_conversion:
      enabled: true # Convert resource attributes to metric labels
extensions:
service:
  extensions:
  pipelines:
    metrics:
      receivers: [otlp, hostmetrics]
      exporters: [prometheus]
    metrics/out:
      receivers: [prometheus]
      processors: [resource/os, resource/boomi]
      exporters: [prometheusremotewrite/apicametrics]
    logs/out:
      receivers: [filelog/container]
      processors: [resource/os, resource/boomi, resource/apicalogs]
      exporters: [apica/logs]
